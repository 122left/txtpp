# Text to Vectors

_Here_ is where the hands-on stuff truly begins.

The pipeline goes like this:

Tokenisation -> Lemmatisation -> Vector generation -> Feature selection

## Tokenisation

Types: word, subword, character, sentence
Special characters: always treated as delimiters, except . , : - ' (context-dependant)

[Tokenisation!]